{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Reduction Tale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    "> * Compare operations taking place in different data containers\n",
    "> * Compare sizes for these data containers\n",
    "> * Help deciding when it is best to use a container or another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we are going to need reductions a lot and we want to choose the best container for performing them.  First, let's start by activating our MemWatcher agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [1] used 0.000 MiB RAM in 0.001s, peaked 0.000 MiB above current, total RAM usage 42.395 MiB\n"
     ]
    }
   ],
   "source": [
    "from ipython_memwatcher import MemWatcher\n",
    "mw = MemWatcher()\n",
    "mw.start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and choose a different container for the data that we want to reduce, starting with a list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 312.688 MiB RAM in 1.963s, peaked 0.000 MiB above current, total RAM usage 355.082 MiB\n"
     ]
    }
   ],
   "source": [
    "a = [float(i) for i in range(10*1000*1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, proceed with a simple reduction (sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 52 ms per loop\n",
      "In [3] used -1.723 MiB RAM in 2.232s, peaked 0.000 MiB above current, total RAM usage 353.359 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which, in MFLOPS (Mega-FloatingPointOps-Per-Second) is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS: 192.3\n",
      "In [4] used 0.000 MiB RAM in 0.003s, peaked 0.000 MiB above current, total RAM usage 353.359 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MFLOPS:\", round((len(a) / t.best / 1e6), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that seems fast, but we don't have other references to compare with.  In addition, a list is not the best kind of container in terms of space consumption.  So let's try now a container that seems quite optimal in terms of memory savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 12.570 MiB RAM in 0.179s, peaked 0.000 MiB above current, total RAM usage 365.930 MiB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [6] used 76.176 MiB RAM in 0.392s, peaked 0.000 MiB above current, total RAM usage 442.105 MiB\n"
     ]
    }
   ],
   "source": [
    "na = np.array(a, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE: 76.294\n",
      "In [7] used 0.000 MiB RAM in 0.003s, peaked 0.000 MiB above current, total RAM usage 442.105 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"SIZE:\", round((na.size * na.itemsize) / 2**20., 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, with 8 bytes/element, NumPy is a very efficient container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 943 ms per loop\n",
      "In [8] used 0.250 MiB RAM in 3.882s, peaked 0.000 MiB above current, total RAM usage 442.355 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o sum(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS: 10.608\n",
      "In [9] used 0.000 MiB RAM in 0.003s, peaked 0.000 MiB above current, total RAM usage 442.355 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance for NumPy is several times slower than the computation with the list.  Why so?\n",
    "\n",
    "*Hint: * We are using sum() which is a Python function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a lot of overhead in producing a Python integer for every element in the array for feeding it to the sum().\n",
    "\n",
    "*Hint:* Use internal NumPy methods (ufuncs) when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.38 ms per loop\n",
      "In [10] used 0.000 MiB RAM in 1.859s, peaked 0.000 MiB above current, total RAM usage 442.355 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o na.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 2281.905\n",
      "In [11] used 0.000 MiB RAM in 0.004s, peaked 0.000 MiB above current, total RAM usage 442.355 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"FLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more than 100x the speed of sum() on a Python list and it is also pretty optimal in terms of both execution time and space consumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The speed in the above reduction is limited by memory speed, not CPU speed.  Could you provide a hint on the maximum memory speed that supports your laptop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.00151538116094"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 0.000 MiB RAM in 0.019s, peaked 0.000 MiB above current, total RAM usage 442.355 MiB\n"
     ]
    }
   ],
   "source": [
    "# This is an easy one.  Just divide the size of the dataset by the time that takes the reduction\n",
    "(na.size * na.itemsize) / t.best / 2**30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case the memory bandwidth is ~ 17 GB/s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using compressed in-memory containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let us suppose that we have really big data to process in our laptop and want to see if we can store our data in less space.  Enter compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "bcolz version:     1.1.1.dev20\n",
      "bcolz git info:    b'1.1.0-20-g50a83ca'\n",
      "NumPy version:     1.11.0\n",
      "Blosc version:     1.9.3 ($Date:: 2016-07-06 #$)\n",
      "Blosc compressors: ['blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib']\n",
      "Numexpr version:   2.5.2\n",
      "Dask version:      0.9.0\n",
      "Python version:    3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Platform:          linux-x86_64\n",
      "Byte-ordering:     little\n",
      "Detected cores:    4\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [46] used 0.004 MiB RAM in 0.018s, peaked 0.000 MiB above current, total RAM usage 647.863 MiB\n"
     ]
    }
   ],
   "source": [
    "import bcolz\n",
    "bcolz.print_versions()\n",
    "bcolz.defaults.cparams['cname'] = 'blosclz'\n",
    "bcolz.defaults.cparams['clevel'] = 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.SHUFFLE\n",
    "bcolz.set_nthreads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [76] used 0.000 MiB RAM in 0.044s, peaked 0.000 MiB above current, total RAM usage 741.758 MiB\n"
     ]
    }
   ],
   "source": [
    "ca = bcolz.carray(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem_used: 0.0\n",
      "In [77] used 0.000 MiB RAM in 0.002s, peaked 0.000 MiB above current, total RAM usage 741.758 MiB\n"
     ]
    }
   ],
   "source": [
    "print(\"mem_used:\", mw.measurements.memory_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this time the amount of memory used seems much lower.  Also, bcolz containers can provide an estimation on how much memory they are taking; let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((10000000,), float64)\n",
       "  nbytes := 76.29 MB; cbytes := 1018.33 KB; ratio: 76.72\n",
       "  cparams := cparams(clevel=9, shuffle=1, cname='blosclz', quantize=0)\n",
       "  chunklen := 65536; chunksize: 524288; blocksize: 524288\n",
       "[  0.00000000e+00   1.00000000e+00   2.00000000e+00 ...,   9.99999700e+06\n",
       "   9.99999800e+06   9.99999900e+06]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [78] used 0.000 MiB RAM in 0.007s, peaked 0.000 MiB above current, total RAM usage 741.758 MiB\n"
     ]
    }
   ],
   "source": [
    "ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that bcolz estimation is reasonably close to `ipython_memwatcher` measurements.  Let's have a look at the speed of the reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 20 ms per loop\n",
      "MFLOPS: 500.668\n",
      "In [79] used 0.000 MiB RAM in 0.906s, peaked 0.000 MiB above current, total RAM usage 741.758 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o ca.sum()\n",
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is around 2~5x slower (depending on the machine) than a regular NumPy array, but the size of the array is an impressive 76x smaller.  But is compression the only responsible of the overhead?  Let's investigate a bit further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using uncompressed containers with bcolz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In order to see if this is because of the compression overhead, let's use an uncompressed array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [51] used 76.250 MiB RAM in 0.428s, peaked 0.266 MiB above current, total RAM usage 725.949 MiB\n"
     ]
    }
   ],
   "source": [
    "cau = bcolz.carray(a, cparams=bcolz.cparams(clevel=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carray((10000000,), float64)\n",
       "  nbytes := 76.29 MB; cbytes := 76.50 MB; ratio: 1.00\n",
       "  cparams := cparams(clevel=0, shuffle=1, cname='blosclz', quantize=0)\n",
       "  chunklen := 65536; chunksize: 524288; blocksize: 8192\n",
       "[  0.00000000e+00   1.00000000e+00   2.00000000e+00 ...,   9.99999700e+06\n",
       "   9.99999800e+06   9.99999900e+06]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [52] used 0.000 MiB RAM in 0.006s, peaked 0.000 MiB above current, total RAM usage 725.949 MiB\n"
     ]
    }
   ],
   "source": [
    "cau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 12.5 ms per loop\n",
      "MFLOPS: 801.816\n",
      "In [80] used 0.000 MiB RAM in 5.271s, peaked 0.000 MiB above current, total RAM usage 741.758 MiB\n"
     ]
    }
   ],
   "source": [
    "t = %timeit -o cau.sum()\n",
    "print(\"MFLOPS:\", round(len(a) / t.best / 1e6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the times with an uncompressed `carray` are between 1.5x and 2x faster than with a compressed one, so compressing is not the only source of the overhead.  The other source of the difference is the memory layout of the different containers (bcolz's carray data container layout is a bit more complex than NumPy).\n",
    "\n",
    "So, while bcolz allows to use compressed in-memory data containers, this usually represents more cost in performance (compared with NumPy).  But sometimes you may prefer to keep more data in-memory and assume that the computations are going to be slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "bcolz uses Blosc, a multithreaded meta-compressor, to do the compression under the hood.  Blosc can use different codecs, and each one has different behavior in terms of performance.  Given the next computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 20.1 ms per loop\n",
      "In [58] used 0.000 MiB RAM in 0.936s, peaked 0.000 MiB above current, total RAM usage 741.566 MiB\n"
     ]
    }
   ],
   "source": [
    "bcolz.defaults.cparams['cname'] = 'blosclz'\n",
    "bcolz.defaults.cparams['clevel'] = 9\n",
    "bcolz.defaults.cparams['shuffle'] = bcolz.SHUFFLE\n",
    "bcolz.set_nthreads(4)\n",
    "ca = bcolz.carray(na)\n",
    "%timeit ca.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the different parameters and see:\n",
    "\n",
    "1) Which provides the best compression\n",
    "\n",
    "2) Which the fastest speed\n",
    "\n",
    "3) The combination that strikes a good balance between compression and performance"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
